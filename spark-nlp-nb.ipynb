{"cells":[{"cell_type":"code","source":["#run the code on Databricks cluster\nimport pyspark\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.appName('nlp').getOrCreate()\ndata = spark.read.csv(\"/FileStore/tables/SMSSpamCollection\",inferSchema=True,sep='\\t')\ndata = data.withColumnRenamed('_c0','class').withColumnRenamed('_c1','text')\ndata.show()\n"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["from pyspark.sql.functions import length\ndata = data.withColumn('length',length(data['text']))\ndata.show()\n# Pretty Clear Difference\ndata.groupby('class').mean().show()\n"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["from pyspark.ml.feature import Tokenizer,StopWordsRemover, CountVectorizer,IDF,StringIndexer\ntokenizer = Tokenizer(inputCol=\"text\", outputCol=\"token_text\")\nstopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\ncount_vec = CountVectorizer(inputCol='stop_tokens',outputCol='c_vec')\nidf = IDF(inputCol=\"c_vec\", outputCol=\"tf_idf\")\nham_spam_to_num = StringIndexer(inputCol='class',outputCol='label')\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.linalg import Vector\nclean_up = VectorAssembler(inputCols=['tf_idf','length'],outputCol='features')\nfrom pyspark.ml.classification import NaiveBayes\nnb = NaiveBayes()\nfrom pyspark.ml import Pipeline\ndata_prep_pipe = Pipeline(stages=[ham_spam_to_num,tokenizer,stopremove,count_vec,idf,clean_up])\ncleaner = data_prep_pipe.fit(data)\nclean_data = cleaner.transform(data)\nclean_data = clean_data.select(['label','features'])\nclean_data.show()\n(training,testing) = clean_data.randomSplit([0.7,0.3])"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["from pyspark.ml.classification import NaiveBayes\nnb = NaiveBayes()\nspam_predictor = nb.fit(training)\ntest_results = spam_predictor.transform(testing)\ntest_results.show()\n"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["from pyspark.ml.evaluation import MulticlassClassificationEvaluator\nacc_eval = MulticlassClassificationEvaluator()\nacc = acc_eval.evaluate(test_results)\nprint(\"Accuracy of NaiveBayes model at predicting spam was: {}\".format(acc))"],"metadata":{},"outputs":[],"execution_count":5}],"metadata":{"name":"spark-nlp","notebookId":3407689208301142},"nbformat":4,"nbformat_minor":0}
